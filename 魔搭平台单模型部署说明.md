# 🎯 魔搭平台单模型部署说明

## 📌 重要说明

你的项目支持**双模型架构**,但也完全兼容**单模型模式**!

### 双模型架构 vs 单模型模式

#### 双模型架构(推荐)
- **生成模型**: `deepseek-chat` - 用于AI对话生成
- **分析模型**: `deepseek-reasoner` - 用于消息分析、检测等

**优势**:
- 更强的推理能力(用于分析)
- 更好的对话质量(用于生成)
- 性能更优

#### 单模型模式(简化版)
- **统一模型**: `deepseek-chat` - 同时用于生成和分析

**优势**:
- 配置简单
- 只需一个API密钥
- 成本更低

## ✅ 单模型部署(最简配置)

### 魔搭平台环境变量

**只需配置3个变量**:

| 变量名 | 值 | 说明 |
|--------|-----|------|
| `MODEL_NAME` | `deepseek-chat` | 主模型 |
| `OPENAI_API_KEY` | `sk-你的密钥` | API密钥 |
| `OPENAI_BASE_URL` | `https://api.deepseek.com/v1` | API地址 |

**不需要配置**:
- ❌ `DETECTION_MODEL_NAME` - 会自动使用 `MODEL_NAME`
- ❌ `DETECTION_API_KEY` - 会自动使用 `OPENAI_API_KEY`
- ❌ `DETECTION_BASE_URL` - 会自动使用 `OPENAI_BASE_URL`

### 启动日志

单模型模式下,你会看到:
```
ℹ️ 未配置DETECTION_MODEL_NAME，将使用主模型进行分析（单模型模式）
✓ 生成模型: deepseek-chat (用于发言生成)
✓ 分析模型: deepseek-chat (用于消息分析)
```

## 🚀 双模型部署(完整配置)

如果你想使用双模型架构,获得更好的性能:

### 魔搭平台环境变量

| 变量名 | 值 | 说明 |
|--------|-----|------|
| `MODEL_NAME` | `deepseek-chat` | 生成模型 |
| `OPENAI_API_KEY` | `sk-你的密钥` | 主API密钥 |
| `OPENAI_BASE_URL` | `https://api.deepseek.com/v1` | 主API地址 |
| `DETECTION_MODEL_NAME` | `deepseek-reasoner` | 分析模型 |
| `DETECTION_API_KEY` | `sk-你的密钥` | 分析API密钥(可以相同) |
| `DETECTION_BASE_URL` | `https://api.deepseek.com/v1` | 分析API地址 |

**注意**: `DETECTION_API_KEY` 可以和 `OPENAI_API_KEY` 使用相同的密钥!

### 启动日志

双模型模式下,你会看到:
```
✓ 双模型架构已初始化
  - 生成模型: deepseek-chat (用于发言生成)
  - 分析模型: deepseek-reasoner (用于消息分析)
  - API地址: https://api.deepseek.com/v1
```

## 🔄 代码自动回退机制

你的代码已经实现了智能回退:

```python
# 1. 尝试使用DETECTION_MODEL_NAME
detection_model = os.getenv('DETECTION_MODEL_NAME')

# 2. 如果没有,回退到MODEL_NAME
if not detection_model:
    detection_model = os.getenv('MODEL_NAME')

# 3. API密钥也会自动回退
api_key = os.getenv('DETECTION_API_KEY') or os.getenv('OPENAI_API_KEY')
base_url = os.getenv('DETECTION_BASE_URL') or os.getenv('OPENAI_BASE_URL')
```

这意味着:
- ✅ 不配置 `DETECTION_*` 变量也能正常运行
- ✅ 配置了就使用双模型
- ✅ 没配置就自动回退到单模型

## 📊 性能对比

### 单模型模式
- API调用次数: 正常
- 响应速度: 正常
- 推理能力: 标准
- 成本: 标准

### 双模型模式
- API调用次数: 正常(不会增加)
- 响应速度: 正常
- 推理能力: **更强**(分析任务使用reasoner)
- 成本: 略高(reasoner价格稍高)

## 💡 推荐配置

### 开发/测试环境
使用**单模型模式**:
- 配置简单
- 成本低
- 功能完整

### 生产环境
使用**双模型模式**:
- 性能更好
- 推理更准确
- 用户体验更佳

## 🎯 快速部署

### 单模型部署(3步)

1. **配置环境变量**(魔搭平台):
   ```
   MODEL_NAME=deepseek-chat
   OPENAI_API_KEY=sk-你的密钥
   OPENAI_BASE_URL=https://api.deepseek.com/v1
   ```

2. **提交代码**:
   ```bash
   git push origin master
   ```

3. **重新构建**:
   在魔搭平台点击"重新构建"

### 双模型部署(额外配置)

在单模型基础上,额外添加:
```
DETECTION_MODEL_NAME=deepseek-reasoner
DETECTION_API_KEY=sk-你的密钥
DETECTION_BASE_URL=https://api.deepseek.com/v1
```

## ❓ 常见问题

### Q1: 我只有一个API密钥,能用双模型吗?
**A**: 可以! `DETECTION_API_KEY` 和 `OPENAI_API_KEY` 可以使用相同的密钥。

### Q2: 单模型模式功能会受限吗?
**A**: 不会! 所有功能都正常,只是分析任务也使用 `deepseek-chat` 而不是 `deepseek-reasoner`。

### Q3: 如何切换单模型和双模型?
**A**: 只需在魔搭平台添加或删除 `DETECTION_MODEL_NAME` 环境变量,然后重新构建。

### Q4: 双模型会增加API调用次数吗?
**A**: 不会! 调用次数相同,只是部分调用使用不同的模型。

### Q5: 推荐使用哪种模式?
**A**: 
- 预算有限 → 单模型
- 追求性能 → 双模型
- 不确定 → 先用单模型,随时可以升级

## 📝 总结

你的项目设计得很好,支持灵活的配置:

✅ **最简配置**: 只需3个环境变量(单模型)
✅ **完整配置**: 6个环境变量(双模型)
✅ **自动回退**: 代码会智能处理
✅ **随时切换**: 修改环境变量即可

**建议**: 先用单模型部署,确保能正常运行,然后再考虑升级到双模型。

---

**现在就可以部署了! 🚀**
